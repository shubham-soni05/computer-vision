{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6a0215",
   "metadata": {},
   "source": [
    "# Human Computer Interaction (mouse curser movement , right click, scroll-up, scroll-down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7397ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #hi\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Screen size\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "# Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Euclidean distance\n",
    "def euclidean_distance(p1, p2):\n",
    "    return math.hypot(p2[0] - p1[0], p2[1] - p1[1])\n",
    "\n",
    "# Right click gesture\n",
    "def is_right_click(landmarks, width, height, threshold=30):\n",
    "    thumb_tip = landmarks.landmark[4]\n",
    "    index_tip = landmarks.landmark[8]\n",
    "    x1, y1 = int(thumb_tip.x * width), int(thumb_tip.y * height)\n",
    "    x2, y2 = int(index_tip.x * width), int(index_tip.y * height)\n",
    "    return euclidean_distance((x1, y1), (x2, y2)) < threshold\n",
    "\n",
    "# Finger states\n",
    "def fingers_up(landmarks):\n",
    "    tips_ids = [8, 12, 16, 20]\n",
    "    pip_ids = [6, 10, 14, 18]\n",
    "    return [\n",
    "        1 if landmarks.landmark[tip].y < landmarks.landmark[pip].y else 0\n",
    "        for tip, pip in zip(tips_ids, pip_ids)\n",
    "    ]\n",
    "\n",
    "# Click and scroll flags\n",
    "gesture_log = {\"right_click\": 0, \"scroll_up\": 0, \"scroll_down\": 0}\n",
    "gesture_success = {\"right_click\": 0, \"scroll_up\": 0, \"scroll_down\": 0}\n",
    "last_click_time = 0\n",
    "current_action = \"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = hands.process(rgb_frame)\n",
    "    current_action = \"\"\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Get positions\n",
    "            index_tip = hand_landmarks.landmark[8]\n",
    "            middle_tip = hand_landmarks.landmark[12]\n",
    "            x1, y1 = int(index_tip.x * w), int(index_tip.y * h)\n",
    "            x2, y2 = int(middle_tip.x * w), int(middle_tip.y * h)\n",
    "\n",
    "            # Check if 8 and 12 are close\n",
    "            if euclidean_distance((x1, y1), (x2, y2)) < 40:\n",
    "                # Control mouse cursor using index finger\n",
    "                screen_x = int(index_tip.x * screen_width)\n",
    "                screen_y = int(index_tip.y * screen_height)\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "                current_action = \"Mouse Control\"\n",
    "\n",
    "            # Right click\n",
    "            if is_right_click(hand_landmarks, w, h):\n",
    "                gesture_log[\"right_click\"] += 1\n",
    "                current_time = time.time()\n",
    "                if current_time - last_click_time > 1:\n",
    "                    pyautogui.leftClick()\n",
    "                    last_click_time = current_time\n",
    "                    gesture_success[\"right_click\"] += 1\n",
    "                    current_action = \"Right Click\"\n",
    "\n",
    "            # Scroll Gesture\n",
    "            fingers = fingers_up(hand_landmarks)\n",
    "            if fingers.count(1) == 3:  # Exactly 3 fingers up\n",
    "                if fingers[:3] == [1, 1, 1]:\n",
    "                    gesture_log[\"scroll_up\"] += 1\n",
    "                    pyautogui.scroll(100)\n",
    "                    gesture_success[\"scroll_up\"] += 1\n",
    "                    current_action = \"Scrolling Up\"\n",
    "            elif fingers == [0, 0, 0, 0]:  # All 4 fingers down\n",
    "                gesture_log[\"scroll_down\"] += 1\n",
    "                pyautogui.scroll(-100)\n",
    "                gesture_success[\"scroll_down\"] += 1\n",
    "                current_action = \"Scrolling Down\"\n",
    "\n",
    "            # Draw hand\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Show current action on screen\n",
    "    if current_action:\n",
    "        cv2.putText(frame, current_action, (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Mouse Control\", frame)\n",
    "    time.sleep(0.05)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print Accuracy Report\n",
    "print(\"\\n--- Gesture Accuracy Report ---\")\n",
    "for gesture in gesture_log:\n",
    "    total = gesture_log[gesture]\n",
    "    success = gesture_success[gesture]\n",
    "    accuracy = (success / total * 100) if total > 0 else 0\n",
    "    print(f\"{gesture.title()}:\")\n",
    "    print(f\"  Detected: {total}\")\n",
    "    print(f\"  Performed: {success}\")\n",
    "    print(f\"  Accuracy: {accuracy:.2f}%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
